{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommNet(nn.Module):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        '''\n",
    "        args = (\n",
    "        agent_num: int,\n",
    "        hid_size: int,\n",
    "        obs_size: [int],\n",
    "        continuous: bool,\n",
    "        action_dim: [int],\n",
    "        comm_iters: int,\n",
    "        init_std: float,\n",
    "        'lrate': float,\n",
    "        'batch_size': int,\n",
    "        'max_steps': int,\n",
    "        'gamma': float,\n",
    "        'mean_ratio': float,\n",
    "        'normalize_rewards': bool,\n",
    "        'advantages_per_action': bool,\n",
    "        'value_coeff': float,\n",
    "        'entr': float\n",
    "        )\n",
    "        args is a namedtuple, e.g. args = collections.namedtuple()\n",
    "        '''\n",
    "        super(CommNet, self).__init__()\n",
    "        self.args = args\n",
    "        # create a model\n",
    "        self.construct_model()\n",
    "        # initialize parameters with normal distribution with mean of 0\n",
    "        map(self.init_weights, self.parameters())\n",
    "    \n",
    "    def mask_obs(self, x):\n",
    "        x_lens = [len(x_) for x_ in x]\n",
    "        x_len_max = np.max(x_lens)\n",
    "        for i in range(len(x_lens)):\n",
    "            if x_lens[i] < x_len_max:\n",
    "                x[i] = np.concatenate((x[i], np.zeros(x_len_max-x_len)), axis=0)\n",
    "        return x\n",
    "    \n",
    "    def construct_model(self):\n",
    "        '''\n",
    "        define the model of vanilla CommNet\n",
    "        '''\n",
    "        # encoder transforms observation to latent variables\n",
    "        self.encoder = nn.Linear(self.args.obs_size, self.args.hid_size)\n",
    "        # communication mask where the diagnal should be 0\n",
    "        self.comm_mask = torch.ones(self.args.agent_num, self.args.agent_num) - torch.eye(self.args.agent_num, self.args.agent_num)\n",
    "        # decoder transforms hidden states to action vector\n",
    "        if self.args.continuous:\n",
    "            self.action_mean = nn.Linear(self.args.hid_size, self.args.action_dim)\n",
    "            self.action_log_std = nn.Parameter(torch.zeros(1, self.args.action_dim))\n",
    "        else:\n",
    "            self.action_head = nn.Linear(self.args.hid_size, self.args.action_dim)\n",
    "        # define communication inference\n",
    "        self.f_module = nn.Linear(self.args.hid_size, self.args.hid_size)\n",
    "        self.f_modules = nn.ModuleList([self.f_module for _ in range(self.args.comm_iters)])\n",
    "        # define communication encoder\n",
    "        self.C_module = nn.Linear(self.args.hid_size, self.args.hid_size)\n",
    "        self.C_modules = nn.ModuleList([self.C_module for _ in range(self.args.comm_iters)])\n",
    "        # define value function\n",
    "        self.value_head = nn.Linear(self.args.hid_size, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def state_encoder(self, x):\n",
    "        '''\n",
    "        define a single forward pass of communication inference\n",
    "        '''\n",
    "        return self.tanh(self.encoder(self.mask_obs(x)))\n",
    "\n",
    "    def get_agent_mask(self, batch_size, info):\n",
    "        '''\n",
    "        define the getter of agent mask to confirm the living agent\n",
    "        '''\n",
    "        n = self.args.agent_num\n",
    "        with torch.no_grad():\n",
    "            if 'alive_mask' in info:\n",
    "                agent_mask = torch.from_numpy(info['alive_mask'])\n",
    "                num_agents_alive = agent_mask.sum()\n",
    "            else:\n",
    "                agent_mask = torch.ones(n)\n",
    "                num_agents_alive = n\n",
    "        # shape = (1, 1, n)\n",
    "        agent_mask = agent_mask.view(1, 1, n)\n",
    "        # shape = (batch_size, n ,n, 1)\n",
    "        agent_mask = agent_mask.expand(batch_size, n, n).unsqueeze(-1)\n",
    "        return num_agents_alive, agent_mask\n",
    "\n",
    "    def action(self, obs, info={}):\n",
    "        '''\n",
    "        define the action process of vanilla CommNet\n",
    "        '''\n",
    "        length = 0\n",
    "        for o in obs:\n",
    "            if o.shape[0] > length:\n",
    "                length = o.shape[0]\n",
    "        i = 0\n",
    "        for o in obs:\n",
    "            if o.shape[0] < length:\n",
    "                obs[i] = np.concatenate((o, np.zeros(length-o.shape[0])))\n",
    "            i += 1\n",
    "        with torch.no_grad():\n",
    "            obs = torch.tensor(np.array(obs)).float().unsqueeze(0)\n",
    "        # encode observation\n",
    "        h = self.state_encoder(obs)\n",
    "        # get the batch size\n",
    "        batch_size = obs.size()[0]\n",
    "        # get the total number of agents including dead\n",
    "        n = self.args.agent_num\n",
    "        # get the agent mask\n",
    "        num_agents_alive, agent_mask = self.get_agent_mask(batch_size, info)\n",
    "        # conduct the main process of communication\n",
    "        for i in range(self.args.comm_iters):\n",
    "            # shape = (batch_size, n, hid_size)->(batch_size, n, 1, hid_size)->(batch_size, n, n, hid_size)\n",
    "            h_ = h.unsqueeze(-2).expand(-1, n, n, self.args.hid_size)\n",
    "            # construct the communication mask\n",
    "            mask = self.comm_mask.view(1, n, n) # shape = (1, n, n)\n",
    "            mask = mask.expand(batch_size, n, n) # shape = (batch_size, n, n)\n",
    "            mask = mask.unsqueeze(-1) # shape = (batch_size, n, n, 1)\n",
    "            mask = mask.expand_as(h_) # shape = (batch_size, n, n, hid_size)\n",
    "            # mask each agent itself (collect the hidden state of other agents)\n",
    "            h_ = h_ * mask\n",
    "            # mask the dead agent\n",
    "            h_ = h_ * agent_mask * agent_mask.transpose(1, 2)\n",
    "            # average the hidden state\n",
    "            h_ = h_ / (num_agents_alive - 1)\n",
    "            # calculate the communication vector\n",
    "            c = h_.sum(dim=1) if i != 0 else torch.zeros_like(h) # shape = (batch_size, n, hid_size)\n",
    "            # h_{j}^{i+1} = \\sigma(H_j * h_j^{i+1} + C_j * c_j^{i+1})\n",
    "            h = self.tanh(sum([self.f_modules[i](h), self.C_modules[i](c)]))\n",
    "        # calculate the value function (critic)\n",
    "        value_head = self.value_head(h)\n",
    "        # calculate the action vector (actor)\n",
    "        if self.args.continuous:\n",
    "            # shape = (batch_size, n, action_dim)\n",
    "            action_mean = self.action_mean(h)\n",
    "            action_log_std = self.action_log_std.expand_as(action_mean)\n",
    "            action_std = torch.exp(action_log_std)\n",
    "            # will be used later to sample\n",
    "            action = (action_mean, action_log_std, action_std)\n",
    "        else:\n",
    "            # discrete actions, shape = (batch_size, n, action_type, action_num)\n",
    "            action = F.log_softmax(self.action_head(h), dim=-1)\n",
    "        return action, value_head\n",
    "    \n",
    "    def forward(self, obs, info={}):\n",
    "        return self.action(obs, info)\n",
    "    \n",
    "    def init_weights(self, m):\n",
    "        '''\n",
    "        initialize the weights of parameters\n",
    "        '''\n",
    "        if type(m) == nn.Linear:\n",
    "            m.weight.data.normal_(0, self.args.init_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from inspect import getargspec\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_stat(src, dest):\n",
    "    for k, v in src.items():\n",
    "        if not k in dest:\n",
    "            dest[k] = v\n",
    "        elif isinstance(v, numbers.Number):\n",
    "            dest[k] = dest.get(k, 0) + v\n",
    "        elif isinstance(v, np.ndarray): # for rewards in case of multi-agent\n",
    "            dest[k] = dest.get(k, 0) + v\n",
    "        else:\n",
    "            if isinstance(dest[k], list) and isinstance(v, list):\n",
    "                dest[k].extend(v)\n",
    "            elif isinstance(dest[k], list):\n",
    "                dest[k].append(v)\n",
    "            else:\n",
    "                dest[k] = [dest[k], v]\n",
    "\n",
    "def normal_entropy(std):\n",
    "    var = std.pow(2)\n",
    "    entropy = 0.5 + 0.5 * torch.log(2 * var * math.pi)\n",
    "    return entropy.sum(1, keepdim=True)\n",
    "\n",
    "def normal_log_density(x, mean, log_std, std):\n",
    "    var = std.pow(2)\n",
    "    log_density = -(x - mean).pow(2) / (2 * var) - 0.5 * math.log(2 * math.pi) - log_std\n",
    "    return log_density.sum(1, keepdim=True)\n",
    "\n",
    "def multinomials_log_density(actions, log_probs):\n",
    "    log_prob = 0\n",
    "    for i in range(len(log_probs)):\n",
    "        log_prob += log_probs[i].gather(1, actions[:, i].long().unsqueeze(1))\n",
    "    return log_prob\n",
    "\n",
    "def multinomials_log_densities(actions, log_probs):\n",
    "    log_prob = [0] * len(log_probs)\n",
    "    for i in range(len(log_probs)):\n",
    "        log_prob[i] += log_probs[i].gather(1, actions[:, i].long().unsqueeze(1))\n",
    "    log_prob = torch.cat(log_prob, dim=-1)\n",
    "    return log_prob\n",
    "\n",
    "def select_action(args, action_out):\n",
    "    if args.continuous:\n",
    "        action_mean, _, action_std = action_out\n",
    "        action = torch.normal(action_mean, action_std)\n",
    "        return action.detach()\n",
    "    else:\n",
    "        log_p_a = action_out\n",
    "        p_a = [[z.exp() for z in x] for x in log_p_a]\n",
    "        ret = torch.stack([torch.stack([torch.multinomial(x, 1).detach() for x in p]) for p in p_a])\n",
    "        return ret\n",
    "\n",
    "def translate_action(args, env, action):\n",
    "    # This is different from the source code\n",
    "    if args.action_num > 0:\n",
    "        action_tensor = torch.zeros(tuple(action.size()[:-1])+(args.action_num,))\n",
    "        action_tensor.scatter_(-1, action, 1)\n",
    "        # environment takes discrete action\n",
    "        actual = [action_tensor[:, i, :].squeeze().data.numpy() for i in range(action_tensor.size(1))]\n",
    "        action = np.array(actual)\n",
    "        return action, actual\n",
    "    else:\n",
    "        if args.continuous:\n",
    "            action = action.data[0].numpy()\n",
    "            cp_action = action.copy()\n",
    "            # clip and scale action to correct range\n",
    "            for i in range(len(action)):\n",
    "                low = env.action_space.low[i]\n",
    "                high = env.action_space.high[i]\n",
    "                cp_action[i] = cp_action[i] * args.action_scale\n",
    "                cp_action[i] = max(-1.0, min(cp_action[i], 1.0))\n",
    "                cp_action[i] = 0.5 * (cp_action[i] + 1.0) * (high - low) + low\n",
    "            return action, cp_action\n",
    "        else:\n",
    "            actual = np.zeros(len(action))\n",
    "            for i in range(len(action)):\n",
    "                low = env.action_space.low[i]\n",
    "                high = env.action_space.high[i]\n",
    "                actual[i] = action[i].data.squeeze()[0] * (high - low) / (args.naction_heads[i] - 1) + low\n",
    "            action = [x.squeeze().data[0] for x in action]\n",
    "            return action, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a transition of an episode\n",
    "Transition = namedtuple('Transition', ('state', 'action', 'action_out', 'value', 'episode_mask', 'episode_mini_mask', 'next_state', 'reward', 'misc'))\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self, args, policy_net, env):\n",
    "        self.args = args\n",
    "        self.policy_net = policy_net\n",
    "        self.env = env\n",
    "        self.optimizer = optim.RMSprop(policy_net.parameters(), lr = args.lrate, alpha=0.97, eps=1e-6)\n",
    "        self.params = [p for p in self.policy_net.parameters()]\n",
    "\n",
    "    def get_episode(self):\n",
    "        # define the episode list\n",
    "        episode = []\n",
    "        # reset the environment\n",
    "        state = self.env.reset()\n",
    "        # set up two auxilliary dictionaries\n",
    "        stat = dict()\n",
    "        info = dict()\n",
    "        # define the main process of exploration\n",
    "        for t in range(self.args.max_steps):\n",
    "            plt.imshow(np.array(self.env.render(mode='rgb_array')).squeeze())\n",
    "            display.display(plt.gcf())    \n",
    "            display.clear_output()\n",
    "            misc = dict()\n",
    "            # decide the next action and return the correlated state value (baseline)\n",
    "            action_out, value = self.policy_net.action(state, info)\n",
    "            # return the sampled actions of all of agents\n",
    "            action = select_action(self.args, action_out)\n",
    "            # return the rescaled (clipped) actions\n",
    "            _, actual = translate_action(self.args, self.env, action)\n",
    "            # receive the reward and the next state\n",
    "            next_state, reward, done, info = self.env.step(actual)\n",
    "            # record the alive agents\n",
    "            if 'alive_mask' in info:\n",
    "                # serve for the starcraft environment\n",
    "                misc['alive_mask'] = info['alive_mask'].reshape(reward.shape)\n",
    "            else:\n",
    "                misc['alive_mask'] = np.ones_like(reward)\n",
    "            # define the flag of the finish of exploration\n",
    "            done = done or t == self.args.max_steps - 1\n",
    "\n",
    "            reward = np.array(reward)\n",
    "            episode_mask = np.ones(reward.shape)\n",
    "            episode_mini_mask = np.ones(reward.shape)\n",
    "\n",
    "            if done:\n",
    "                episode_mask = np.zeros(reward.shape)\n",
    "            else:\n",
    "                # serve for traffic environment\n",
    "                if 'is_completed' in info:\n",
    "                    episode_mini_mask = 1 - info['is_completed'].reshape(-1)\n",
    "            # record a transition\n",
    "            trans = Transition(state, action, action_out, value, episode_mask, episode_mini_mask, next_state, reward, misc)\n",
    "            # record the current transition to the whole episode\n",
    "            episode.append(trans)\n",
    "\n",
    "            state = next_state\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "        stat['num_steps'] = t + 1\n",
    "        stat['steps_taken'] = stat['num_steps']\n",
    "        return (episode, stat)\n",
    "\n",
    "    def compute_grad(self, batch):\n",
    "\n",
    "        stat = dict()\n",
    "\n",
    "        action_dim = self.args.action_dim\n",
    "        n = self.args.agent_num\n",
    "        batch_size = len(batch.state)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            rewards = torch.Tensor(batch.reward)\n",
    "            \n",
    "            episode_masks = torch.Tensor(batch.episode_mask)\n",
    "            episode_mini_masks = torch.Tensor(batch.episode_mini_mask)\n",
    "            batch_action = torch.stack(batch.action, dim=0).float()\n",
    "            actions = torch.Tensor(batch_action)\n",
    "            actions = actions.transpose(1, 2).view(-1, n, 1)\n",
    "\n",
    "        values = torch.cat(batch.value, dim=0)\n",
    "        action_out = list(zip(*batch.action_out))\n",
    "        action_out = [torch.cat(a, dim=0) for a in action_out]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            alive_masks = torch.Tensor(np.concatenate([item['alive_mask'] for item in batch.misc])).view(-1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            coop_returns = torch.Tensor(batch_size, n)\n",
    "            ncoop_returns = torch.Tensor(batch_size, n)\n",
    "            returns = torch.Tensor(batch_size, n)\n",
    "            # deltas = torch.Tensor(batch_size, n)\n",
    "            advantages = torch.Tensor(batch_size, n)\n",
    "            values = values.view(batch_size, n)\n",
    "\n",
    "        prev_coop_return = 0\n",
    "        prev_ncoop_return = 0\n",
    "        prev_value = 0\n",
    "        prev_advantage = 0\n",
    "        \n",
    "        # calculate the return reversely and the reward is shared\n",
    "        for i in reversed(range(rewards.size(0))):\n",
    "            coop_returns[i] = rewards[i] + self.args.gamma * prev_coop_return * episode_masks[i]\n",
    "            ncoop_returns[i] = rewards[i] + self.args.gamma * prev_ncoop_return * episode_masks[i] * episode_mini_masks[i]\n",
    "\n",
    "            prev_coop_return = coop_returns[i]\n",
    "            prev_ncoop_return = ncoop_returns[i]\n",
    "\n",
    "            returns[i] = (self.args.mean_ratio * coop_returns[i].mean()) \\\n",
    "                         + ((1 - self.args.mean_ratio) * ncoop_returns[i])\n",
    "        \n",
    "        # calculate the advantage\n",
    "        for i in reversed(range(rewards.size(0))):\n",
    "            advantages[i] = returns[i] - values.data[i]\n",
    "        \n",
    "        # normalize the advantage\n",
    "        if self.args.normalize_rewards:\n",
    "            advantages = (advantages - advantages.mean()) / advantages.std()\n",
    "        \n",
    "        # take the policy of the actions\n",
    "        if self.args.continuous:\n",
    "            action_means, action_log_stds, action_stds = action_out\n",
    "            log_prob = normal_log_density(actions, action_means, action_log_stds, action_stds)\n",
    "        else:\n",
    "            log_p_a = action_out\n",
    "            actions = actions.contiguous().view(-1, 1)\n",
    "            if self.args.advantages_per_action:\n",
    "                log_prob = multinomials_log_densities(actions, log_p_a)\n",
    "            else:\n",
    "                log_prob = multinomials_log_density(actions, log_p_a)\n",
    "\n",
    "        if self.args.advantages_per_action:\n",
    "            action_loss = -advantages.view(-1).unsqueeze(-1) * log_prob\n",
    "            action_loss *= alive_masks.unsqueeze(-1)\n",
    "        else:\n",
    "            action_loss = -advantages.view(-1) * log_prob.squeeze()\n",
    "            action_loss *= alive_masks\n",
    "\n",
    "        action_loss = action_loss.sum()\n",
    "        stat['action_loss'] = action_loss.item()\n",
    "\n",
    "        # value loss term\n",
    "        targets = returns\n",
    "        value_loss = (values - targets).pow(2).view(-1)\n",
    "        value_loss *= alive_masks\n",
    "        value_loss = value_loss.sum()\n",
    "        stat['value_loss'] = value_loss.item()\n",
    "\n",
    "        loss = action_loss + self.args.value_coeff * value_loss\n",
    "\n",
    "        if not self.args.continuous:\n",
    "            # entropy regularization term\n",
    "            entropy = 0\n",
    "            for i in range(len(log_p_a)):\n",
    "                entropy -= (log_p_a[i] * log_p_a[i].exp()).sum()\n",
    "            stat['entropy'] = entropy.item()\n",
    "            if self.args.entr > 0:\n",
    "                loss -= self.args.entr * entropy\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        return stat\n",
    "\n",
    "    def run_batch(self):\n",
    "        batch = []\n",
    "        self.stats = dict()\n",
    "        self.stats['num_episodes'] = 0\n",
    "        while len(batch) < self.args.batch_size:\n",
    "            if self.args.batch_size - len(batch) <= self.args.max_steps:\n",
    "                self.last_step = True\n",
    "            episode, episode_stat = self.get_episode()\n",
    "            # merge_stat(episode_stat, self.stats)\n",
    "            self.stats['num_episodes'] += 1\n",
    "            batch += episode\n",
    "\n",
    "        self.last_step = False\n",
    "        self.stats['num_steps'] = len(batch)\n",
    "        batch = Transition(*zip(*batch))\n",
    "        return batch, self.stats\n",
    "\n",
    "    def train_batch(self):\n",
    "        batch, stat = self.run_batch()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        s = self.compute_grad(batch)\n",
    "        merge_stat(s, stat)\n",
    "        for p in self.params:\n",
    "            if p._grad is not None:\n",
    "                p._grad.data /= stat['num_steps']\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import spaces\n",
    "\n",
    "\n",
    "class GymWrapper(object):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        self.obs_space = self.env.observation_space\n",
    "        self.act_space = self.env.action_space\n",
    "    \n",
    "    def __call__(self):\n",
    "        return self.env\n",
    "    \n",
    "    def get_num_of_agents(self):\n",
    "        return self.env.n\n",
    "    \n",
    "    def get_shape_of_obs(self):\n",
    "        obs_shapes = []\n",
    "        for obs in self.obs_space:\n",
    "            if isinstance(obs, spaces.Box):\n",
    "                obs_shapes.append(obs.shape)\n",
    "        assert len(self.obs_space) == len(obs_shapes)\n",
    "        return obs_shapes\n",
    "        \n",
    "    def get_output_shape_of_act(self):\n",
    "        act_shapes = []\n",
    "        for act in self.act_space:\n",
    "            if isinstance(act, spaces.Discrete):\n",
    "                act_shapes.append(act.n)\n",
    "            elif isinstance(act, spaces.MultiDiscrete):\n",
    "                act_shapes.append(act.high - act.low + 1)\n",
    "            elif isinstance(act, spaces.Boxes):\n",
    "                assert act.shape == 1\n",
    "                act_shapes.append(act.shape)\n",
    "        return act_shapes\n",
    "    \n",
    "    def get_dtype_of_obs(self):\n",
    "        return [obs.dtype for obs in self.obs_space]\n",
    "    \n",
    "    def get_input_shape_of_act(self):\n",
    "        act_shapes = []\n",
    "        for act in self.act_space:\n",
    "            if isinstance(act, spaces.Discrete):\n",
    "                act_shapes.append(act.n)\n",
    "            elif isinstance(act, spaces.MultiDiscrete):\n",
    "                act_shapes.append(act.shape)\n",
    "            elif isinstance(act, spaces.Boxes):\n",
    "                assert act.shape == 1\n",
    "                act_shapes.append(act.shape)\n",
    "        return act_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiagent.environment import MultiAgentEnv\n",
    "import multiagent.scenarios as scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5315a93b81f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'This is the epoch: {} and the current advantage is: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-23096d00efb1>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-23096d00efb1>\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_stat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;31m# merge_stat(episode_stat, self.stats)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_episodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-23096d00efb1>\u001b[0m in \u001b[0;36mget_episode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mmisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2076\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \"\"\"\n\u001b[0;32m--> 510\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0mtoolbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoolbar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1649\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2626\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2628\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 584\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    837\u001b[0m         return self._make_image(\n\u001b[1;32m    838\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             unsampled=unsampled)\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;31m# Always convert to RGBA, even if only RGB input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rgb_to_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gym/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_rgb_to_rgba\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \"\"\"\n\u001b[1;32m    171\u001b[0m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scenario_name = 'simple_tag'\n",
    "# scenario_name = 'simple_world_comm'\n",
    "\n",
    "# load scenario from script\n",
    "scenario = scenario.load(scenario_name + \".py\").Scenario()\n",
    "# create world\n",
    "world = scenario.make_world()\n",
    "# create multiagent environment\n",
    "env = MultiAgentEnv(world, scenario.reset_world, scenario.reward, scenario.observation, info_callback=None, shared_viewer=True)\n",
    "\n",
    "env = GymWrapper(env)\n",
    "\n",
    "Args = namedtuple('Args', ['agent_num',\n",
    "                           'hid_size',\n",
    "                           'obs_size',\n",
    "                           'continuous',\n",
    "                           'action_dim',\n",
    "                           'comm_iters',\n",
    "                           'init_std',\n",
    "                           'lrate',\n",
    "                           'batch_size',\n",
    "                           'max_steps',\n",
    "                           'gamma',\n",
    "                           'mean_ratio',\n",
    "                           'normalize_rewards',\n",
    "                           'advantages_per_action',\n",
    "                           'value_coeff',\n",
    "                           'entr',\n",
    "                           'action_num'\n",
    "                          ]\n",
    "                 )\n",
    "\n",
    "args = Args(agent_num=env.get_num_of_agents(),\n",
    "            hid_size=100,\n",
    "            obs_size=np.max(env.get_shape_of_obs()),\n",
    "            continuous=False,\n",
    "            action_dim=np.max(env.get_output_shape_of_act()),\n",
    "            comm_iters=100,\n",
    "            init_std=0.2,\n",
    "            lrate=0.001,\n",
    "            batch_size=32,\n",
    "            max_steps=200,\n",
    "            gamma=0.99,\n",
    "            mean_ratio=0,\n",
    "            normalize_rewards=True,\n",
    "            advantages_per_action=False,\n",
    "            value_coeff=0.001,\n",
    "            entr=0.001,\n",
    "            action_num=np.max(env.get_input_shape_of_act())\n",
    "           )\n",
    "\n",
    "policy_net = CommNet(args)\n",
    "epoch = 0\n",
    "for i in range(1000):\n",
    "    train = Trainer(args, policy_net, env())\n",
    "    train.train_batch()\n",
    "    print ('This is the epoch: {} and the current advantage is: {}'.format(epoch, train.stats['action_loss']))\n",
    "    epoch += 1\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('This is the scenario observation: \\n', dir(env))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dir(env().observation_space[0]))\n",
    "print (dir(env().action_space[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (env()._get_obs(env().agents[1]))\n",
    "print (env()._get_reward(env().agents[1]))\n",
    "print (env().action_space)\n",
    "print (env().observation_space)\n",
    "print (env().agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
